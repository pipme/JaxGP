{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sgpr_heteroskedastic)=\n",
    "\n",
    "# SGPR regression with heteroskedastic noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "import jax\n",
    "import copy\n",
    "import jaxgp as jgp\n",
    "import jax.numpy as jnp\n",
    "from jaxgp.sgpr_heteroskedastic import HeteroskedasticSGPR\n",
    "import jaxopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jaxgp.contrib.train_utils import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(123)\n",
    "\n",
    "\n",
    "def readCsvFile(fileName):\n",
    "    return np.loadtxt(fileName).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def getTrainingTestData():\n",
    "    overallX = readCsvFile(\"data/snelson_train_inputs.dat\")\n",
    "    overallY = readCsvFile(\"data/snelson_train_outputs.dat\")\n",
    "\n",
    "    trainIndices = []\n",
    "    testIndices = []\n",
    "\n",
    "    nPoints = overallX.shape[0]\n",
    "\n",
    "    for index in range(nPoints):\n",
    "        if index % 4 == 0:\n",
    "            trainIndices.append(index)\n",
    "        else:\n",
    "            testIndices.append(index)\n",
    "\n",
    "    Xtrain = overallX[trainIndices, :]\n",
    "    Xtest = overallX[testIndices, :]\n",
    "    Ytrain = overallY[trainIndices, :]\n",
    "    Ytest = overallY[testIndices, :]\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "\n",
    "X, y, Xtest, ytest = getTrainingTestData()\n",
    "inds = jnp.argsort(X[:, 0])\n",
    "X = X[inds]\n",
    "y = y[inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check with SGPR with homoscedastic noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.copy()[::5]\n",
    "train_data = jgp.Dataset(X=X, Y=y)\n",
    "kernel = jgp.kernels.RBF(active_dims=tuple(range(X.shape[-1])))\n",
    "mean = jgp.means.Quadratic(input_dim=X.shape[-1])\n",
    "model = HeteroskedasticSGPR(\n",
    "    train_data=train_data,\n",
    "    gprior=jgp.GPrior(kernel=kernel, mean_function=mean),\n",
    "    likelihood=jgp.likelihoods.Gaussian(),\n",
    "    inducing_points=Z,\n",
    ")\n",
    "\n",
    "_, constrain_trans, _ = jgp.initialise(model)\n",
    "\n",
    "# soln = train_model(model, fixed_params={\"inducing_points\": Z})\n",
    "soln = train_model(model)\n",
    "posterior = model.posterior()\n",
    "final_params = constrain_trans(soln.params)\n",
    "# print(final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print params' shape info\n",
    "params_container = copy.deepcopy(soln.params)\n",
    "params_container = jax.tree_map(lambda v: v.shape, params_container)\n",
    "print(params_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = jnp.linspace(-3, 10, 100)\n",
    "pred_mean, pred_var = posterior.predict_f(Xtest, final_params, full_cov=False)\n",
    "plt.plot(X, y, \"o\", color=\"k\", markersize=2)\n",
    "plt.plot(\n",
    "    final_params[\"inducing_points\"], np.zeros_like(Z), \"x\", color=\"tab:red\"\n",
    ")\n",
    "plt.plot(Xtest, pred_mean, color=\"tab:orange\", linewidth=2)\n",
    "plt.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    pred_mean.squeeze() - 2 * np.sqrt(pred_var.squeeze()),\n",
    "    pred_mean.squeeze() + 2 * np.sqrt(pred_var.squeeze()),\n",
    "    alpha=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qu_mean, qu_cov = model.compute_qu(final_params)\n",
    "f_at_Z_mean, f_at_Z_cov = posterior.predict_f(\n",
    "    final_params[\"inducing_points\"], final_params, full_cov=True\n",
    ")\n",
    "assert jnp.allclose(qu_mean, f_at_Z_mean, rtol=1e-5, atol=1e-3)\n",
    "assert jnp.allclose(\n",
    "    qu_cov.reshape(1, Z.shape[0], Z.shape[0]), f_at_Z_cov, rtol=1e-5, atol=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroskedastic noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.copy()[::5]\n",
    "train_data = jgp.Dataset(X=X, Y=y)\n",
    "kernel = jgp.kernels.RBF(active_dims=tuple(range(X.shape[-1])))\n",
    "mean = jgp.means.Constant()\n",
    "noise_variance = jnp.concatenate(\n",
    "    [\n",
    "        0.01 * jnp.ones(X.shape[0] // 2),\n",
    "        1.0 * jnp.ones(X.shape[0] - X.shape[0] // 2),\n",
    "    ]\n",
    ")\n",
    "model = HeteroskedasticSGPR(\n",
    "    train_data=train_data,\n",
    "    gprior=jgp.GPrior(kernel=kernel, mean_function=mean),\n",
    "    likelihood=jgp.likelihoods.FixedHeteroskedasticGaussian(),\n",
    "    sigma_sq_user=noise_variance,\n",
    "    inducing_points=Z,\n",
    ")\n",
    "\n",
    "_, constrain_trans, _ = jgp.initialise(model)\n",
    "\n",
    "# soln = train_model(model, fixed_params={\"inducing_points\": X})\n",
    "soln = train_model(model)\n",
    "posterior = model.posterior()\n",
    "final_params = constrain_trans(soln.params)\n",
    "print(\"After optimization negative elbo = \", soln.state.fun_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = jnp.linspace(-3, 10, 100)\n",
    "Xtest = jnp.concatenate([X[:, 0], Xtest])\n",
    "Xtest = jnp.sort(Xtest)\n",
    "pred_mean, pred_var = posterior.predict_f(Xtest, final_params, full_cov=False)\n",
    "plt.plot(X, y, \"o\", color=\"k\", markersize=2)\n",
    "plt.plot(\n",
    "    final_params[\"inducing_points\"], np.zeros_like(Z), \"x\", color=\"tab:red\"\n",
    ")\n",
    "plt.plot(Xtest, pred_mean, color=\"tab:orange\", linewidth=2)\n",
    "plt.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    pred_mean.squeeze() - 2 * np.sqrt(pred_var.squeeze()),\n",
    "    pred_mean.squeeze() + 2 * np.sqrt(pred_var.squeeze()),\n",
    "    alpha=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with exact GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxgp.gpr import GPR\n",
    "\n",
    "train_data = jgp.Dataset(X=X, Y=y)\n",
    "kernel = jgp.kernels.RBF(active_dims=tuple(range(X.shape[-1])))\n",
    "mean = jgp.means.Constant()\n",
    "noise_variance = jnp.concatenate(\n",
    "    [\n",
    "        0.01 * jnp.ones(X.shape[0] // 2),\n",
    "        1.0 * jnp.ones(X.shape[0] - X.shape[0] // 2),\n",
    "    ]\n",
    ")\n",
    "model = GPR(\n",
    "    train_data=train_data,\n",
    "    gprior=jgp.GPrior(kernel=kernel, mean_function=mean),\n",
    "    sigma_sq=noise_variance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, constrain_trans, _ = jgp.initialise(model)\n",
    "soln = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params_exact_gp = constrain_trans(soln.params)\n",
    "gp_post = model.posterior(final_params_exact_gp)\n",
    "pred_mean_exact_gp, pred_var_exact_gp = gp_post.predict_f(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, y, \"o\", color=\"k\", markersize=2)\n",
    "plt.plot(\n",
    "    final_params[\"inducing_points\"], np.zeros_like(Z), \"x\", color=\"tab:red\"\n",
    ")\n",
    "plt.plot(\n",
    "    Xtest, pred_mean_exact_gp, color=\"tab:red\", linewidth=2, label=\"Exact GP\"\n",
    ")\n",
    "plt.plot(Xtest, pred_mean, color=\"tab:orange\", linewidth=2, label=\"SGPR\")\n",
    "plt.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    pred_mean_exact_gp.squeeze() - 2 * np.sqrt(pred_var_exact_gp.squeeze()),\n",
    "    pred_mean_exact_gp.squeeze() + 2 * np.sqrt(pred_var_exact_gp.squeeze()),\n",
    "    alpha=0.5,\n",
    "    color=\"tab:blue\",\n",
    "    label=\"Exact GP\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    pred_mean.squeeze() - 2 * np.sqrt(pred_var.squeeze()),\n",
    "    pred_mean.squeeze() + 2 * np.sqrt(pred_var.squeeze()),\n",
    "    alpha=0.3,\n",
    "    color=\"tab:green\",\n",
    "    label=\"SGPR\",\n",
    ")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73de991c5b87fa789d9b193d807aa508bc59c930638e53d55560bd0f6da949df"
  },
  "kernelspec": {
   "display_name": "py39_forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
