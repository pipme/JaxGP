{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(svgp)=\n",
    "\n",
    "# SVGP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxopt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import jaxgp as jgp\n",
    "from jaxgp.datasets import Dataset, CustomDataset, NumpyLoader\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "num_data = 1000\n",
    "num_test = 1000\n",
    "num_inducing = 50\n",
    "batch_size = 60\n",
    "\n",
    "\n",
    "def func(X):\n",
    "    return np.sin(2 * X) + 0.3 * X + np.random.normal(0, 0.1, X.shape)\n",
    "\n",
    "\n",
    "X = np.random.uniform(-3.0, 3.0, (num_data, input_dim))\n",
    "Y = func(X)\n",
    "\n",
    "key = jax.random.PRNGKey(10)\n",
    "\n",
    "Xtest = jnp.sort(\n",
    "    jax.random.uniform(key, shape=(num_test, input_dim), minval=-5, maxval=5),\n",
    "    0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = jgp.means.Quadratic()\n",
    "kernel = jgp.kernels.RBF()\n",
    "gprior = jgp.GPrior(kernel=kernel, mean_function=mean)\n",
    "likelihood = jgp.likelihoods.Gaussian()\n",
    "inducing_points = (\n",
    "    jax.random.uniform(key=key, shape=(num_inducing, input_dim))\n",
    "    * (X.max() - X.min())\n",
    "    + X.min()\n",
    ")\n",
    "model = jgp.SVGP(gprior, likelihood, inducing_points, output_dim)\n",
    "\n",
    "params, constrain_trans, unconstrain_trans = jgp.initialise(model)\n",
    "raw_params = unconstrain_trans(params)\n",
    "neg_elbo = model.build_elbo(num_data=num_data, sign=-1.0)\n",
    "\n",
    "training_data = CustomDataset(X, Y)\n",
    "train_dataloader = NumpyLoader(\n",
    "    training_data, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jax.value_and_grad\n",
    "def loss(raw_params, batch):\n",
    "    return neg_elbo(raw_params, batch)\n",
    "\n",
    "\n",
    "opt = optax.adam(learning_rate=1e-3)\n",
    "opt_state = opt.init(raw_params)\n",
    "\n",
    "num_epochs = 400\n",
    "loss_history = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch in train_dataloader:\n",
    "        data = Dataset(X=batch[0], Y=batch[1])\n",
    "        loss_val, grads = loss(raw_params, data)\n",
    "        updates, opt_state = opt.update(grads, opt_state)\n",
    "        raw_params = optax.apply_updates(raw_params, updates)\n",
    "    loss_history.append(loss_val.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_history, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(params):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y, \"kx\", mew=2, alpha=0.5, label=\"data points\")\n",
    "    plt.plot(\n",
    "        params[\"inducing_points\"],\n",
    "        jnp.zeros([num_inducing, input_dim]),\n",
    "        \"|\",\n",
    "        color=\"tab:red\",\n",
    "        mew=2,\n",
    "        alpha=0.5,\n",
    "        label=\"inducing_points\",\n",
    "    )\n",
    "    mean, var = model.predict_y(params, Xtest)\n",
    "    plt.plot(Xtest, mean, \"tab:orange\", lw=2, label=\"predicted mean\")\n",
    "    plt.fill_between(\n",
    "        Xtest[:, 0],\n",
    "        mean[:, 0] - 1.96 * jnp.sqrt(var[:, 0]),\n",
    "        mean[:, 0] + 1.96 * jnp.sqrt(var[:, 0]),\n",
    "        color=\"tab:blue\",\n",
    "        alpha=0.5,\n",
    "        label=\"95% confidence region\",\n",
    "    )\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = constrain_trans(raw_params)\n",
    "plot_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be29132aef35e5fa4aa5c8a1d39197c9d5b550114bb18652724c256d8861a162"
  },
  "kernelspec": {
   "display_name": "py39_forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
